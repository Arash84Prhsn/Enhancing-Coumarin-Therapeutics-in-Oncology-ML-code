{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "372d9abb",
   "metadata": {},
   "source": [
    "# All code regarding the paper is in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1af5f6a",
   "metadata": {},
   "source": [
    "## HistGradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd40058",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, median_absolute_error, make_scorer\n",
    "import os\n",
    "import sys\n",
    "from joblib import dump\n",
    "\n",
    "# Please Change the paths to match your own enviroment.(in case of failure that is)\n",
    "DATA_PATH = 'Total_Data.csv'\n",
    "\n",
    "CURRENT_MODEL = \"HistGradientBoostingRegressor\";\n",
    "\n",
    "RESULT_DIR = os.path.join(os.getcwd(), f'TrainingResults/Models/{CURRENT_MODEL}/')\n",
    "os.makedirs(RESULT_DIR, exist_ok=True)\n",
    "\n",
    "mainData = pd.read_csv(DATA_PATH);\n",
    "\n",
    "mainData = mainData[['Cancer Type', 'Coumarin Type', 'Coumarin Dose', 'Time', 'Viability']].dropna();\n",
    "\n",
    "allowed_times_NoAuraptene = [24, 48, 72]\n",
    "allowed_times_ForAuraptene = [24, 48, 72, 96]\n",
    "\n",
    "coumarins = ['Auraptene', 'Esculetin', 'Galbanic Acid', 'Umbelliprenin'];\n",
    "\n",
    "# ====<Pre-Processing and GMM filtering>====\n",
    "\n",
    "#First filter the main data and save it in data.\n",
    "cancer_counts = mainData['Cancer Type'].value_counts().to_dict()\n",
    "count_df = pd.DataFrame(list(cancer_counts.items()), columns=['Cancer Type', 'Sample Count'])\n",
    "\n",
    "#Initialize the gmm model\n",
    "gmm = GaussianMixture(n_components=2, random_state=42);\n",
    "gmm.fit(count_df[['Sample Count']])\n",
    "threshold = np.mean(gmm.means_.flatten())\n",
    "\n",
    "count_df['Reliability'] = count_df['Sample Count'].apply(\n",
    "    lambda x: 'Reliable' if x >= threshold else 'Unreliable'\n",
    ")\n",
    "\n",
    "reliable_cancers = count_df[count_df['Reliability'] == 'Reliable']['Cancer Type'].tolist()\n",
    "reliable_data = mainData[mainData['Cancer Type'].isin(reliable_cancers)].copy()\n",
    "\n",
    "data = reliable_data;\n",
    "CancerType_Encoder = LabelEncoder();\n",
    "CoumarinType_Encoder = LabelEncoder();\n",
    "\n",
    "data['Coumarin Type'] = CoumarinType_Encoder.fit_transform(data['Coumarin Type'])\n",
    "data['Cancer Type'] = CancerType_Encoder.fit_transform(data['Cancer Type'])\n",
    "\n",
    "# Filter out the unneeded times for the general data\n",
    "data = data[\n",
    "    ((data['Coumarin Type'] == 'Auraptene') & data['Time'].isin(allowed_times_ForAuraptene)) |\n",
    "    ((data['Coumarin Type'] != 'Auraptene') & data['Time'].isin(allowed_times_NoAuraptene))\n",
    "]\n",
    "\n",
    "\n",
    "# Wether we intend to do grid searching on the model or not is denoted the variable below:\n",
    "DO_GRIDSEARCH = False;\n",
    "\n",
    "# Set your X and y here, incase you want general training or training on a specific coumarin.\n",
    "\n",
    "X = data[['Cancer Type', 'Coumarin Type', 'Coumarin Dose', 'Time']].copy(); # Order must be ['Cancer Type', 'Coumarin Type', 'Coumarin Dose', 'Time']\n",
    "y = data['Viability'].copy(); # Viability column\n",
    "\n",
    "# ====<BEGIN GRID SEARCHING>====\n",
    "# Grid searching is done here, the program stops after grid searching and the parameters and the scores are all saved in reports directory:\n",
    "if DO_GRIDSEARCH :\n",
    "    \n",
    "    gs_Estimator = HistGradientBoostingRegressor(random_state=42);\n",
    "    \n",
    "    # The parameters for the search.\n",
    "    gs_parameters = {\n",
    "        \"learning_rate\": [0.01,0.03,0.05,0.07],  # 4\n",
    "        \"max_depth\": [3,5,7],                    # 3\n",
    "        \"max_leaf_nodes\": [31,63,127],           # 3\n",
    "        \"min_samples_leaf\": [5,10,20],           # 3\n",
    "        \"l2_regularization\": [0.0,0.1,0.5],      # 3\n",
    "        \"loss\": [\"squared_error\", \"absolute_error\"] # 2\n",
    "    }\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42);\n",
    "    gs = GridSearchCV(estimator=gs_Estimator,\n",
    "                                scoring='r2',\n",
    "                                param_grid=gs_parameters,\n",
    "                                cv=kf,\n",
    "                                n_jobs=-1,\n",
    "                                verbose=1\n",
    "                                );\n",
    "    \n",
    "    gs.fit(X, y);\n",
    "\n",
    "    BEST_MODEL_PARAMETERS = gs.best_params_;\n",
    "    BEST_MODEL_R2_SCORE = gs.best_score_;\n",
    "\n",
    "    dict = BEST_MODEL_PARAMETERS.copy()\n",
    "    dict['R2'] = BEST_MODEL_R2_SCORE;\n",
    "    \n",
    "    df = pd.DataFrame(dict, index=[0]);\n",
    "\n",
    "    # Save the best found parameters\n",
    "    os.makedirs(f\"{RESULT_DIR}Best_Paremeters/\", exist_ok=True);\n",
    "    df.to_csv(f\"{RESULT_DIR}Best_Paremeters/{CURRENT_MODEL}_GS_BestParameters.csv\",index=False);\n",
    "\n",
    "    sys.exit(0);\n",
    "# ====<END OF GRID SEARCHING>====\n",
    "\n",
    "# ====<START EVALUATING MODEL>====\n",
    "# Get the model parameters post GridSearching\n",
    "params = pd.read_csv(f\"{RESULT_DIR}Best_Paremeters/{CURRENT_MODEL}_GS_BestParameters.csv\").iloc[0].to_dict();\n",
    "\n",
    "# Helper function to make sure the hyperParameters are read correctly.\n",
    "def sanitize_params(estimator, params):\n",
    "    \n",
    "    \"\"\"\n",
    "    Cleans and fixes parameter types before passing them to sklearn models.\n",
    "    - Converts floats representing ints into int\n",
    "    - Converts 'None' strings to None\n",
    "    - Converts NaN to None\n",
    "    - Removes unexpected params\n",
    "    \"\"\"\n",
    "\n",
    "    valid_params = estimator().get_params().keys()\n",
    "    clean = {}\n",
    "\n",
    "    for key, value in params.items():\n",
    "\n",
    "        # Skip invalid params\n",
    "        if key not in valid_params:\n",
    "            continue\n",
    "\n",
    "        # Convert string 'None' to Python None\n",
    "        if isinstance(value, str) and value.strip().lower() == \"none\":\n",
    "            clean[key] = None\n",
    "            continue\n",
    "\n",
    "        # Convert NaN to None\n",
    "        if isinstance(value, float) and np.isnan(value):\n",
    "            clean[key] = None\n",
    "            continue\n",
    "\n",
    "        # Convert float-like integers to real ints\n",
    "        if isinstance(value, float) and value.is_integer():\n",
    "            clean[key] = int(value)\n",
    "            continue\n",
    "\n",
    "        # Leave everything else unchanged\n",
    "        clean[key] = value\n",
    "\n",
    "    return clean\n",
    "\n",
    "params.pop(\"R2\");\n",
    "params = sanitize_params(HistGradientBoostingRegressor, params=params)\n",
    "params['random_state'] = 42\n",
    "\n",
    "# feed the params to model, with random_state as 42\n",
    "model = HistGradientBoostingRegressor(**params);\n",
    "\n",
    "# Start Evaluating Model performance. Get R2, MAE, RMSE\n",
    "cv_Scores = {\"R2\" : None, \"MAE\" : None, \"MSE\" : None, \"MedAE\" : None};\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42);\n",
    "\n",
    "scorers = {\n",
    "    \"R2\": \"r2\",\n",
    "    \"MAE\": make_scorer(mean_absolute_error, greater_is_better=False),\n",
    "    \"MSE\": make_scorer(mean_squared_error, greater_is_better=False),\n",
    "    \"MedAE\" : make_scorer(median_absolute_error, greater_is_better=False)\n",
    "}\n",
    "\n",
    "for score_type, scorer in scorers.items() :\n",
    "    score = cross_val_score(estimator=model, scoring=scorer, X=X, y=y, cv=kf, n_jobs=-1, verbose=0).mean()\n",
    "    if score_type in [\"MAE\", \"MSE\", \"MedAE\"] :\n",
    "        score = -score;\n",
    "    \n",
    "    cv_Scores[score_type] = score;\n",
    "\n",
    "df = pd.DataFrame(cv_Scores, index=[0])\n",
    "\n",
    "# save the evaluation results\n",
    "os.makedirs(f\"{RESULT_DIR}Evaluations/\", exist_ok=True);\n",
    "df.to_csv(f\"{RESULT_DIR}Evaluations/{CURRENT_MODEL}_Evaluation_Report.csv\",index=False);\n",
    "# ====<DONE EVAlUATING THE MODEL>====\n",
    "\n",
    "# Train the model on our X and y \n",
    "model.fit(X,y)\n",
    "\n",
    "\n",
    "def predict_viability(model, cancer_type, coumarin_type, dose, time, \n",
    "                      cancer_encoder, coumarin_encoder):\n",
    "    \"\"\"\n",
    "    Predict viability for a single input or a list of inputs.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: trained sklearn regressor\n",
    "    - cancer_type: string or list of strings\n",
    "    - coumarin_type: string or list of strings\n",
    "    - dose: float or list of floats\n",
    "    - time: float or list of floats\n",
    "    - cancer_encoder: LabelEncoder for cancer types\n",
    "    - coumarin_encoder: LabelEncoder for coumarin types (general) or specific coumarin\n",
    "\n",
    "    Returns:\n",
    "    - predicted viability (float or np.array)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure inputs are lists\n",
    "    if not isinstance(cancer_type, list):\n",
    "        cancer_type = [cancer_type]\n",
    "        coumarin_type = [coumarin_type]\n",
    "        dose = [dose]\n",
    "        time = [time]\n",
    "\n",
    "    # Encode categorical variables\n",
    "    cancer_encoded = cancer_encoder.transform(cancer_type)\n",
    "    coumarin_encoded = coumarin_encoder.transform(coumarin_type)\n",
    "\n",
    "    # Build DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'Cancer Type': cancer_encoded,\n",
    "        'Coumarin Type': coumarin_encoded,\n",
    "        'Coumarin Dose': dose,\n",
    "        'Time': time\n",
    "    })\n",
    "\n",
    "    # Predict\n",
    "    predictions = model.predict(df)\n",
    "\n",
    "    # If input was a single value, return single prediction\n",
    "    if len(predictions) == 1:\n",
    "        return predictions[0]\n",
    "    return predictions\n",
    "\n",
    "predicted_viability = predict_viability(\n",
    "    model=model,\n",
    "    cancer_type=\"Colon\",        # example cancer type\n",
    "    coumarin_type=\"Auraptene\", # example coumarin\n",
    "    dose=75,                    # dose value\n",
    "    time=72,                    # time value\n",
    "    cancer_encoder=CancerType_Encoder,\n",
    "    coumarin_encoder=CoumarinType_Encoder\n",
    ")\n",
    "\n",
    "print(f\"Viability with a dose of 240 (galbanic acid) at 72h time point: {predicted_viability}\")\n",
    "doses = [91, 75, 71];\n",
    "times = [24,48,72];\n",
    "\n",
    "for d, t in zip(doses, times) :\n",
    "    predicted_viability = predict_viability(\n",
    "    model=model,\n",
    "    cancer_type=\"Colon\",        # example cancer type\n",
    "    coumarin_type=\"Auraptene\", # example coumarin\n",
    "    dose=d,                    # dose value\n",
    "    time=t,                    # time value\n",
    "    cancer_encoder= CancerType_Encoder,\n",
    "    coumarin_encoder= CoumarinType_Encoder\n",
    "    )\n",
    "    print(f\"Predicted Viability with Dose {d} (auraptene) at time {t} is: {predicted_viability}\");\n",
    "\n",
    "\n",
    "os.makedirs(f\"{RESULT_DIR}/ModelFile/\", exist_ok=True);\n",
    "dump(model, f\"{RESULT_DIR}/ModelFile/{CURRENT_MODEL}.joblib\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe2ff40",
   "metadata": {},
   "source": [
    "## GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffaa051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, median_absolute_error, make_scorer\n",
    "import os\n",
    "import sys\n",
    "from joblib import dump\n",
    "\n",
    "# Please Change the paths to match your own enviroment.(in case of failure that is)\n",
    "DATA_PATH = 'Total_Data.csv'\n",
    "\n",
    "CURRENT_MODEL = \"GradientBoostingRegressor\";\n",
    "\n",
    "RESULT_DIR = os.path.join(os.getcwd(), f'TrainingResults/Models/{CURRENT_MODEL}/')\n",
    "os.makedirs(RESULT_DIR, exist_ok=True)\n",
    "\n",
    "mainData = pd.read_csv(DATA_PATH);\n",
    "\n",
    "mainData = mainData[['Cancer Type', 'Coumarin Type', 'Coumarin Dose', 'Time', 'Viability']].dropna();\n",
    "\n",
    "allowed_times_NoAuraptene = [24, 48, 72]\n",
    "allowed_times_ForAuraptene = [24, 48, 72, 96]\n",
    "\n",
    "coumarins = ['Auraptene', 'Esculetin', 'Galbanic Acid', 'Umbelliprenin'];\n",
    "\n",
    "# ====<Pre-Processing and GMM filtering>====\n",
    "\n",
    "#First filter the main data and save it in data.\n",
    "cancer_counts = mainData['Cancer Type'].value_counts().to_dict()\n",
    "count_df = pd.DataFrame(list(cancer_counts.items()), columns=['Cancer Type', 'Sample Count'])\n",
    "\n",
    "#Initialize the gmm model\n",
    "gmm = GaussianMixture(n_components=2, random_state=42);\n",
    "gmm.fit(count_df[['Sample Count']])\n",
    "threshold = np.mean(gmm.means_.flatten())\n",
    "\n",
    "count_df['Reliability'] = count_df['Sample Count'].apply(\n",
    "    lambda x: 'Reliable' if x >= threshold else 'Unreliable'\n",
    ")\n",
    "\n",
    "reliable_cancers = count_df[count_df['Reliability'] == 'Reliable']['Cancer Type'].tolist()\n",
    "reliable_data = mainData[mainData['Cancer Type'].isin(reliable_cancers)].copy()\n",
    "\n",
    "data = reliable_data;\n",
    "CancerType_Encoder = LabelEncoder();\n",
    "CoumarinType_Encoder = LabelEncoder();\n",
    "\n",
    "data['Coumarin Type'] = CoumarinType_Encoder.fit_transform(data['Coumarin Type'])\n",
    "data['Cancer Type'] = CancerType_Encoder.fit_transform(data['Cancer Type'])\n",
    "\n",
    "# Filter out the unneeded times for the general data\n",
    "data = data[\n",
    "    ((data['Coumarin Type'] == 'Auraptene') & data['Time'].isin(allowed_times_ForAuraptene)) |\n",
    "    ((data['Coumarin Type'] != 'Auraptene') & data['Time'].isin(allowed_times_NoAuraptene))\n",
    "]\n",
    "\n",
    "\n",
    "# Wether we intend to do grid searching on the model or not is denoted the variable below:\n",
    "DO_GRIDSEARCH = False;\n",
    "\n",
    "# Set your X and y here, incase you want general training or training on a specific coumarin.\n",
    "\n",
    "X = data[['Cancer Type', 'Coumarin Type', 'Coumarin Dose', 'Time']].copy(); # Order must be ['Cancer Type', 'Coumarin Type', 'Coumarin Dose', 'Time']\n",
    "y = data['Viability'].copy(); # Viability column\n",
    "\n",
    "# ====<BEGIN GRID SEARCHING>====\n",
    "# Grid searching is done here, the program stops after grid searching and the parameters and the scores are all saved in reports directory:\n",
    "if DO_GRIDSEARCH :\n",
    "    \n",
    "    gs_Estimator = GradientBoostingRegressor(random_state=42);\n",
    "    \n",
    "    # The parameters for the search.\n",
    "    gs_parameters = {\n",
    "        \"n_estimators\": [300, 600, 900, 1200, 1500],\n",
    "        \"learning_rate\": [0.01, 0.03, 0.05, 0.1],\n",
    "        \"max_depth\": [2, 3, 4],\n",
    "        \"subsample\": [0.7, 0.85],\n",
    "        \"max_features\": [None, \"sqrt\"],\n",
    "    }\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42);\n",
    "    gs = GridSearchCV(estimator=gs_Estimator,\n",
    "                                scoring='r2',\n",
    "                                param_grid=gs_parameters,\n",
    "                                cv=kf,\n",
    "                                n_jobs=-1,\n",
    "                                verbose=1\n",
    "                                );\n",
    "    \n",
    "    gs.fit(X, y);\n",
    "\n",
    "    BEST_MODEL_PARAMETERS = gs.best_params_;\n",
    "    BEST_MODEL_R2_SCORE = gs.best_score_;\n",
    "\n",
    "    dict = BEST_MODEL_PARAMETERS.copy()\n",
    "    dict['R2'] = BEST_MODEL_R2_SCORE;\n",
    "    \n",
    "    df = pd.DataFrame(dict, index=[0]);\n",
    "\n",
    "    # Save the best found parameters\n",
    "    os.makedirs(f\"{RESULT_DIR}Best_Paremeters/\", exist_ok=True);\n",
    "    df.to_csv(f\"{RESULT_DIR}Best_Paremeters/{CURRENT_MODEL}_GS_BestParameters.csv\",index=False);\n",
    "\n",
    "    sys.exit(0);\n",
    "# ====<END OF GRID SEARCHING>====\n",
    "\n",
    "# ====<START EVALUATING MODEL>====\n",
    "# Get the model parameters post GridSearching\n",
    "params = pd.read_csv(f\"{RESULT_DIR}Best_Paremeters/{CURRENT_MODEL}_GS_BestParameters.csv\").iloc[0].to_dict();\n",
    "\n",
    "# Helper function to make sure the hyperParameters are read correctly.\n",
    "def sanitize_params(estimator, params):\n",
    "    \n",
    "    \"\"\"\n",
    "    Cleans and fixes parameter types before passing them to sklearn models.\n",
    "    - Converts floats representing ints into int\n",
    "    - Converts 'None' strings to None\n",
    "    - Converts NaN to None\n",
    "    - Removes unexpected params\n",
    "    \"\"\"\n",
    "\n",
    "    valid_params = estimator().get_params().keys()\n",
    "    clean = {}\n",
    "\n",
    "    for key, value in params.items():\n",
    "\n",
    "        # Skip invalid params\n",
    "        if key not in valid_params:\n",
    "            continue\n",
    "\n",
    "        # Convert string 'None' to Python None\n",
    "        if isinstance(value, str) and value.strip().lower() == \"none\":\n",
    "            clean[key] = None\n",
    "            continue\n",
    "\n",
    "        # Convert NaN to None\n",
    "        if isinstance(value, float) and np.isnan(value):\n",
    "            clean[key] = None\n",
    "            continue\n",
    "\n",
    "        # Convert float-like integers to real ints\n",
    "        if isinstance(value, float) and value.is_integer():\n",
    "            clean[key] = int(value)\n",
    "            continue\n",
    "\n",
    "        # Leave everything else unchanged\n",
    "        clean[key] = value\n",
    "\n",
    "    return clean\n",
    "\n",
    "params.pop(\"R2\");\n",
    "params = sanitize_params(GradientBoostingRegressor, params=params)\n",
    "params['random_state'] = 42\n",
    "\n",
    "# feed the params to model, with random_state as 42\n",
    "model = GradientBoostingRegressor(**params);\n",
    "\n",
    "# Start Evaluating Model performance. Get R2, MAE, RMSE\n",
    "cv_Scores = {\"R2\" : None, \"MAE\" : None, \"MSE\" : None, \"MedAE\" : None};\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42);\n",
    "\n",
    "scorers = {\n",
    "    \"R2\": \"r2\",\n",
    "    \"MAE\": make_scorer(mean_absolute_error, greater_is_better=False),\n",
    "    \"MSE\": make_scorer(mean_squared_error, greater_is_better=False),\n",
    "    \"MedAE\" : make_scorer(median_absolute_error, greater_is_better=False)\n",
    "}\n",
    "\n",
    "for score_type, scorer in scorers.items() :\n",
    "    score = cross_val_score(estimator=model, scoring=scorer, X=X, y=y, cv=kf, n_jobs=-1, verbose=0).mean()\n",
    "    if score_type in [\"MAE\", \"MSE\", \"MedAE\"] :\n",
    "        score = -score;\n",
    "    \n",
    "    cv_Scores[score_type] = score;\n",
    "\n",
    "df = pd.DataFrame(cv_Scores, index=[0])\n",
    "\n",
    "# save the evaluation results\n",
    "os.makedirs(f\"{RESULT_DIR}Evaluations/\", exist_ok=True);\n",
    "df.to_csv(f\"{RESULT_DIR}Evaluations/{CURRENT_MODEL}_Evaluation_Report.csv\",index=False);\n",
    "# ====<DONE EVAlUATING THE MODEL>====\n",
    "\n",
    "# Train the model on our X and y \n",
    "model.fit(X,y)\n",
    "\n",
    "\n",
    "def predict_viability(model, cancer_type, coumarin_type, dose, time, \n",
    "                      cancer_encoder, coumarin_encoder):\n",
    "    \"\"\"\n",
    "    Predict viability for a single input or a list of inputs.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: trained sklearn regressor\n",
    "    - cancer_type: string or list of strings\n",
    "    - coumarin_type: string or list of strings\n",
    "    - dose: float or list of floats\n",
    "    - time: float or list of floats\n",
    "    - cancer_encoder: LabelEncoder for cancer types\n",
    "    - coumarin_encoder: LabelEncoder for coumarin types (general) or specific coumarin\n",
    "\n",
    "    Returns:\n",
    "    - predicted viability (float or np.array)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure inputs are lists\n",
    "    if not isinstance(cancer_type, list):\n",
    "        cancer_type = [cancer_type]\n",
    "        coumarin_type = [coumarin_type]\n",
    "        dose = [dose]\n",
    "        time = [time]\n",
    "\n",
    "    # Encode categorical variables\n",
    "    cancer_encoded = cancer_encoder.transform(cancer_type)\n",
    "    coumarin_encoded = coumarin_encoder.transform(coumarin_type)\n",
    "\n",
    "    # Build DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'Cancer Type': cancer_encoded,\n",
    "        'Coumarin Type': coumarin_encoded,\n",
    "        'Coumarin Dose': dose,\n",
    "        'Time': time\n",
    "    })\n",
    "\n",
    "    # Predict\n",
    "    predictions = model.predict(df)\n",
    "\n",
    "    # If input was a single value, return single prediction\n",
    "    if len(predictions) == 1:\n",
    "        return predictions[0]\n",
    "    return predictions\n",
    "\n",
    "predicted_viability = predict_viability(\n",
    "    model=model,\n",
    "    cancer_type=\"Colon\",        # example cancer type\n",
    "    coumarin_type=\"Auraptene\", # example coumarin\n",
    "    dose=75,                    # dose value\n",
    "    time=72,                    # time value\n",
    "    cancer_encoder=CancerType_Encoder,\n",
    "    coumarin_encoder=CoumarinType_Encoder\n",
    ")\n",
    "\n",
    "print(f\"Viability with a dose of 240 (galbanic acid) at 72h time point: {predicted_viability}\")\n",
    "doses = [91, 75, 71];\n",
    "times = [24,48,72];\n",
    "\n",
    "for d, t in zip(doses, times) :\n",
    "    predicted_viability = predict_viability(\n",
    "    model=model,\n",
    "    cancer_type=\"Colon\",        # example cancer type\n",
    "    coumarin_type=\"Auraptene\", # example coumarin\n",
    "    dose=d,                    # dose value\n",
    "    time=t,                    # time value\n",
    "    cancer_encoder= CancerType_Encoder,\n",
    "    coumarin_encoder= CoumarinType_Encoder\n",
    "    )\n",
    "    print(f\"Predicted Viability with Dose {d} (auraptene) at time {t} is: {predicted_viability}\");\n",
    "\n",
    "\n",
    "os.makedirs(f\"{RESULT_DIR}/ModelFile/\", exist_ok=True);\n",
    "dump(model, f\"{RESULT_DIR}/ModelFile/{CURRENT_MODEL}.joblib\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce15fa2",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfb33ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, median_absolute_error, make_scorer\n",
    "import os\n",
    "import sys\n",
    "from joblib import dump\n",
    "\n",
    "# Please Change the paths to match your own enviroment.(in case of failure that is)\n",
    "DATA_PATH = 'Total_Data.csv'\n",
    "\n",
    "CURRENT_MODEL = \"XGBRegressor\";\n",
    "\n",
    "RESULT_DIR = os.path.join(os.getcwd(), f'TrainingResults/Models/{CURRENT_MODEL}/')\n",
    "os.makedirs(RESULT_DIR, exist_ok=True)\n",
    "\n",
    "mainData = pd.read_csv(DATA_PATH);\n",
    "\n",
    "mainData = mainData[['Cancer Type', 'Coumarin Type', 'Coumarin Dose', 'Time', 'Viability']].dropna();\n",
    "\n",
    "allowed_times_NoAuraptene = [24, 48, 72]\n",
    "allowed_times_ForAuraptene = [24, 48, 72, 96]\n",
    "\n",
    "coumarins = ['Auraptene', 'Esculetin', 'Galbanic Acid', 'Umbelliprenin'];\n",
    "\n",
    "# ====<Pre-Processing and GMM filtering>====\n",
    "\n",
    "#First filter the main data and save it in data.\n",
    "cancer_counts = mainData['Cancer Type'].value_counts().to_dict()\n",
    "count_df = pd.DataFrame(list(cancer_counts.items()), columns=['Cancer Type', 'Sample Count'])\n",
    "\n",
    "#Initialize the gmm model\n",
    "gmm = GaussianMixture(n_components=2, random_state=42);\n",
    "gmm.fit(count_df[['Sample Count']])\n",
    "threshold = np.mean(gmm.means_.flatten())\n",
    "\n",
    "count_df['Reliability'] = count_df['Sample Count'].apply(\n",
    "    lambda x: 'Reliable' if x >= threshold else 'Unreliable'\n",
    ")\n",
    "\n",
    "reliable_cancers = count_df[count_df['Reliability'] == 'Reliable']['Cancer Type'].tolist()\n",
    "reliable_data = mainData[mainData['Cancer Type'].isin(reliable_cancers)].copy()\n",
    "\n",
    "data = reliable_data;\n",
    "CancerType_Encoder = LabelEncoder();\n",
    "CoumarinType_Encoder = LabelEncoder();\n",
    "\n",
    "data['Coumarin Type'] = CoumarinType_Encoder.fit_transform(data['Coumarin Type'])\n",
    "data['Cancer Type'] = CancerType_Encoder.fit_transform(data['Cancer Type'])\n",
    "\n",
    "# Filter out the unneeded times for the general data\n",
    "data = data[\n",
    "    ((data['Coumarin Type'] == 'Auraptene') & data['Time'].isin(allowed_times_ForAuraptene)) |\n",
    "    ((data['Coumarin Type'] != 'Auraptene') & data['Time'].isin(allowed_times_NoAuraptene))\n",
    "]\n",
    "\n",
    "\n",
    "# Wether we intend to do grid searching on the model or not is denoted the variable below:\n",
    "DO_GRIDSEARCH = False;\n",
    "\n",
    "# Set your X and y here, incase you want general training or training on a specific coumarin.\n",
    "\n",
    "X = data[['Cancer Type', 'Coumarin Type', 'Coumarin Dose', 'Time']].copy(); # Order must be ['Cancer Type', 'Coumarin Type', 'Coumarin Dose', 'Time']\n",
    "y = data['Viability'].copy(); # Viability column\n",
    "\n",
    "# ====<BEGIN GRID SEARCHING>====\n",
    "# Grid searching is done here, the program stops after grid searching and the parameters and the scores are all saved in reports directory:\n",
    "if DO_GRIDSEARCH :\n",
    "    \n",
    "    gs_Estimator = XGBRegressor(random_state=42);\n",
    "    \n",
    "    # The parameters for the search.\n",
    "    gs_parameters = {\n",
    "        \"n_estimators\": [200, 400, 600],\n",
    "        \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "        \"max_depth\": [3, 5, 7],\n",
    "        \"min_child_weight\": [1, 3],\n",
    "        \"subsample\": [0.8, 1.0],\n",
    "        \"colsample_bytree\": [0.8, 1.0],\n",
    "        \"gamma\": [0, 0.1],\n",
    "        \"reg_alpha\": [0, 0.1],\n",
    "        \"reg_lambda\": [1, 1.5]\n",
    "    }\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42);\n",
    "    gs = GridSearchCV(estimator=gs_Estimator,\n",
    "                                scoring='r2',\n",
    "                                param_grid=gs_parameters,\n",
    "                                cv=kf,\n",
    "                                n_jobs=-1,\n",
    "                                verbose=1\n",
    "                                );\n",
    "    \n",
    "    gs.fit(X, y);\n",
    "\n",
    "    BEST_MODEL_PARAMETERS = gs.best_params_;\n",
    "    BEST_MODEL_R2_SCORE = gs.best_score_;\n",
    "\n",
    "    dict = BEST_MODEL_PARAMETERS.copy()\n",
    "    dict['R2'] = BEST_MODEL_R2_SCORE;\n",
    "    \n",
    "    df = pd.DataFrame(dict, index=[0]);\n",
    "\n",
    "    # Save the best found parameters\n",
    "    os.makedirs(f\"{RESULT_DIR}Best_Paremeters/\", exist_ok=True);\n",
    "    df.to_csv(f\"{RESULT_DIR}Best_Paremeters/{CURRENT_MODEL}_GS_BestParameters.csv\",index=False);\n",
    "\n",
    "    sys.exit(0);\n",
    "# ====<END OF GRID SEARCHING>====\n",
    "\n",
    "# ====<START EVALUATING MODEL>====\n",
    "# Get the model parameters post GridSearching\n",
    "params = pd.read_csv(f\"{RESULT_DIR}Best_Paremeters/{CURRENT_MODEL}_GS_BestParameters.csv\").iloc[0].to_dict();\n",
    "\n",
    "# Helper function to make sure the hyperParameters are read correctly.\n",
    "def sanitize_params(estimator, params):\n",
    "    \n",
    "    \"\"\"\n",
    "    Cleans and fixes parameter types before passing them to sklearn models.\n",
    "    - Converts floats representing ints into int\n",
    "    - Converts 'None' strings to None\n",
    "    - Converts NaN to None\n",
    "    - Removes unexpected params\n",
    "    \"\"\"\n",
    "\n",
    "    valid_params = estimator().get_params().keys()\n",
    "    clean = {}\n",
    "\n",
    "    for key, value in params.items():\n",
    "\n",
    "        # Skip invalid params\n",
    "        if key not in valid_params:\n",
    "            continue\n",
    "\n",
    "        # Convert string 'None' to Python None\n",
    "        if isinstance(value, str) and value.strip().lower() == \"none\":\n",
    "            clean[key] = None\n",
    "            continue\n",
    "\n",
    "        # Convert NaN to None\n",
    "        if isinstance(value, float) and np.isnan(value):\n",
    "            clean[key] = None\n",
    "            continue\n",
    "\n",
    "        # Convert float-like integers to real ints\n",
    "        if isinstance(value, float) and value.is_integer():\n",
    "            clean[key] = int(value)\n",
    "            continue\n",
    "\n",
    "        # Leave everything else unchanged\n",
    "        clean[key] = value\n",
    "\n",
    "    return clean\n",
    "\n",
    "params.pop(\"R2\");\n",
    "params = sanitize_params(XGBRegressor, params=params)\n",
    "params['random_state'] = 42\n",
    "\n",
    "# feed the params to model, with random_state as 42\n",
    "model = XGBRegressor(**params);\n",
    "\n",
    "# Start Evaluating Model performance. Get R2, MAE, RMSE\n",
    "cv_Scores = {\"R2\" : None, \"MAE\" : None, \"MSE\" : None, \"MedAE\" : None};\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42);\n",
    "\n",
    "scorers = {\n",
    "    \"R2\": \"r2\",\n",
    "    \"MAE\": make_scorer(mean_absolute_error, greater_is_better=False),\n",
    "    \"MSE\": make_scorer(mean_squared_error, greater_is_better=False),\n",
    "    \"MedAE\" : make_scorer(median_absolute_error, greater_is_better=False)\n",
    "}\n",
    "\n",
    "for score_type, scorer in scorers.items() :\n",
    "    score = cross_val_score(estimator=model, scoring=scorer, X=X, y=y, cv=kf, n_jobs=-1, verbose=0).mean()\n",
    "    if score_type in [\"MAE\", \"MSE\", \"MedAE\"] :\n",
    "        score = -score;\n",
    "    \n",
    "    cv_Scores[score_type] = score;\n",
    "\n",
    "df = pd.DataFrame(cv_Scores, index=[0])\n",
    "\n",
    "# save the evaluation results\n",
    "os.makedirs(f\"{RESULT_DIR}Evaluations/\", exist_ok=True);\n",
    "df.to_csv(f\"{RESULT_DIR}Evaluations/{CURRENT_MODEL}_Evaluation_Report.csv\",index=False);\n",
    "# ====<DONE EVAlUATING THE MODEL>====\n",
    "\n",
    "# Train the model on our X and y \n",
    "model.fit(X,y)\n",
    "\n",
    "def predict_viability(model, cancer_type, coumarin_type, dose, time, \n",
    "                      cancer_encoder, coumarin_encoder):\n",
    "    \"\"\"\n",
    "    Predict viability for a single input or a list of inputs.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: trained sklearn regressor\n",
    "    - cancer_type: string or list of strings\n",
    "    - coumarin_type: string or list of strings\n",
    "    - dose: float or list of floats\n",
    "    - time: float or list of floats\n",
    "    - cancer_encoder: LabelEncoder for cancer types\n",
    "    - coumarin_encoder: LabelEncoder for coumarin types (general) or specific coumarin\n",
    "\n",
    "    Returns:\n",
    "    - predicted viability (float or np.array)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure inputs are lists\n",
    "    if not isinstance(cancer_type, list):\n",
    "        cancer_type = [cancer_type]\n",
    "        coumarin_type = [coumarin_type]\n",
    "        dose = [dose]\n",
    "        time = [time]\n",
    "\n",
    "    # Encode categorical variables\n",
    "    cancer_encoded = cancer_encoder.transform(cancer_type)\n",
    "    coumarin_encoded = coumarin_encoder.transform(coumarin_type)\n",
    "\n",
    "    # Build DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'Cancer Type': cancer_encoded,\n",
    "        'Coumarin Type': coumarin_encoded,\n",
    "        'Coumarin Dose': dose,\n",
    "        'Time': time\n",
    "    })\n",
    "\n",
    "    # Predict\n",
    "    predictions = model.predict(df)\n",
    "\n",
    "    # If input was a single value, return single prediction\n",
    "    if len(predictions) == 1:\n",
    "        return predictions[0]\n",
    "    return predictions\n",
    "\n",
    "predicted_viability = predict_viability(\n",
    "    model=model,\n",
    "    cancer_type=\"Colon\",        # example cancer type\n",
    "    coumarin_type=\"Auraptene\", # example coumarin\n",
    "    dose=75,                    # dose value\n",
    "    time=72,                    # time value\n",
    "    cancer_encoder=CancerType_Encoder,\n",
    "    coumarin_encoder=CoumarinType_Encoder\n",
    ")\n",
    "\n",
    "print(f\"Viability with a dose of 240 (galbanic acid) at 72h time point: {predicted_viability}\")\n",
    "doses = [91, 75, 71];\n",
    "times = [24,48,72];\n",
    "\n",
    "for d, t in zip(doses, times) :\n",
    "    predicted_viability = predict_viability(\n",
    "    model=model,\n",
    "    cancer_type=\"Colon\",        # example cancer type\n",
    "    coumarin_type=\"Auraptene\", # example coumarin\n",
    "    dose=d,                    # dose value\n",
    "    time=t,                    # time value\n",
    "    cancer_encoder= CancerType_Encoder,\n",
    "    coumarin_encoder= CoumarinType_Encoder\n",
    "    )\n",
    "    print(f\"Predicted Viability with Dose {d} (auraptene) at time {t} is: {predicted_viability}\");\n",
    "\n",
    "\n",
    "os.makedirs(f\"{RESULT_DIR}/ModelFile/\", exist_ok=True);\n",
    "dump(model, f\"{RESULT_DIR}/ModelFile/{CURRENT_MODEL}.joblib\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d5b801",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9982d583",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, median_absolute_error, make_scorer\n",
    "import os\n",
    "import sys\n",
    "from joblib import dump\n",
    "\n",
    "# Please Change the paths to match your own enviroment.(in case of failure that is)\n",
    "DATA_PATH = 'Total_Data.csv'\n",
    "\n",
    "CURRENT_MODEL = \"RandomForestRegressor\";\n",
    "\n",
    "RESULT_DIR = os.path.join(os.getcwd(), f'TrainingResults/Models/{CURRENT_MODEL}/')\n",
    "os.makedirs(RESULT_DIR, exist_ok=True)\n",
    "\n",
    "mainData = pd.read_csv(DATA_PATH);\n",
    "\n",
    "mainData = mainData[['Cancer Type', 'Coumarin Type', 'Coumarin Dose', 'Time', 'Viability']].dropna();\n",
    "\n",
    "allowed_times_NoAuraptene = [24, 48, 72]\n",
    "allowed_times_ForAuraptene = [24, 48, 72, 96]\n",
    "\n",
    "coumarins = ['Auraptene', 'Esculetin', 'Galbanic Acid', 'Umbelliprenin'];\n",
    "\n",
    "# ====<Pre-Processing and GMM filtering>====\n",
    "\n",
    "#First filter the main data and save it in data.\n",
    "cancer_counts = mainData['Cancer Type'].value_counts().to_dict()\n",
    "count_df = pd.DataFrame(list(cancer_counts.items()), columns=['Cancer Type', 'Sample Count'])\n",
    "\n",
    "#Initialize the gmm model\n",
    "gmm = GaussianMixture(n_components=2, random_state=42);\n",
    "gmm.fit(count_df[['Sample Count']])\n",
    "threshold = np.mean(gmm.means_.flatten())\n",
    "\n",
    "count_df['Reliability'] = count_df['Sample Count'].apply(\n",
    "    lambda x: 'Reliable' if x >= threshold else 'Unreliable'\n",
    ")\n",
    "\n",
    "reliable_cancers = count_df[count_df['Reliability'] == 'Reliable']['Cancer Type'].tolist()\n",
    "reliable_data = mainData[mainData['Cancer Type'].isin(reliable_cancers)].copy()\n",
    "\n",
    "data = reliable_data;\n",
    "CancerType_Encoder = LabelEncoder();\n",
    "CoumarinType_Encoder = LabelEncoder();\n",
    "\n",
    "data['Coumarin Type'] = CoumarinType_Encoder.fit_transform(data['Coumarin Type'])\n",
    "data['Cancer Type'] = CancerType_Encoder.fit_transform(data['Cancer Type'])\n",
    "\n",
    "# Filter out the unneeded times for the general data\n",
    "data = data[\n",
    "    ((data['Coumarin Type'] == 'Auraptene') & data['Time'].isin(allowed_times_ForAuraptene)) |\n",
    "    ((data['Coumarin Type'] != 'Auraptene') & data['Time'].isin(allowed_times_NoAuraptene))\n",
    "]\n",
    "\n",
    "\n",
    "# Wether we intend to do grid searching on the model or not is denoted the variable below:\n",
    "DO_GRIDSEARCH = False;\n",
    "\n",
    "# Set your X and y here, incase you want general training or training on a specific coumarin.\n",
    "\n",
    "X = data[['Cancer Type', 'Coumarin Type', 'Coumarin Dose', 'Time']].copy(); # Order must be ['Cancer Type', 'Coumarin Type', 'Coumarin Dose', 'Time']\n",
    "y = data['Viability'].copy(); # Viability column\n",
    "\n",
    "# ====<BEGIN GRID SEARCHING>====\n",
    "# Grid searching is done here, the program stops after grid searching and the parameters and the scores are all saved in reports directory:\n",
    "if DO_GRIDSEARCH :\n",
    "    \n",
    "    gs_Estimator = RandomForestRegressor(random_state=42);\n",
    "    \n",
    "    # The parameters for the search.\n",
    "    gs_parameters = {\n",
    "        \"n_estimators\": [200, 400, 600, 800],          \n",
    "        \"max_depth\": [None, 10, 20, 30],              \n",
    "        \"min_samples_split\": [2, 5, 10],              \n",
    "        \"min_samples_leaf\": [1, 2, 4],                \n",
    "        \"max_features\": [\"sqrt\", \"log2\"],\n",
    "    }\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42);\n",
    "    gs = GridSearchCV(estimator=gs_Estimator,\n",
    "                                scoring='r2',\n",
    "                                param_grid=gs_parameters,\n",
    "                                cv=kf,\n",
    "                                n_jobs=-1,\n",
    "                                verbose=1\n",
    "                                );\n",
    "    \n",
    "    gs.fit(X, y);\n",
    "\n",
    "    BEST_MODEL_PARAMETERS = gs.best_params_;\n",
    "    BEST_MODEL_R2_SCORE = gs.best_score_;\n",
    "\n",
    "    dict = BEST_MODEL_PARAMETERS.copy()\n",
    "    dict['R2'] = BEST_MODEL_R2_SCORE;\n",
    "    \n",
    "    df = pd.DataFrame(dict, index=[0]);\n",
    "\n",
    "    # Save the best found parameters\n",
    "    os.makedirs(f\"{RESULT_DIR}Best_Paremeters/\", exist_ok=True);\n",
    "    df.to_csv(f\"{RESULT_DIR}Best_Paremeters/{CURRENT_MODEL}_GS_BestParameters.csv\",index=False);\n",
    "\n",
    "    sys.exit(0);\n",
    "# ====<END OF GRID SEARCHING>====\n",
    "\n",
    "# ====<START EVALUATING MODEL>====\n",
    "# Get the model parameters post GridSearching\n",
    "params = pd.read_csv(f\"{RESULT_DIR}Best_Paremeters/{CURRENT_MODEL}_GS_BestParameters.csv\").iloc[0].to_dict();\n",
    "\n",
    "# Helper function to make sure the hyperParameters are read correctly.\n",
    "def sanitize_params(estimator, params):\n",
    "    \n",
    "    \"\"\"\n",
    "    Cleans and fixes parameter types before passing them to sklearn models.\n",
    "    - Converts floats representing ints into int\n",
    "    - Converts 'None' strings to None\n",
    "    - Converts NaN to None\n",
    "    - Removes unexpected params\n",
    "    \"\"\"\n",
    "\n",
    "    valid_params = estimator().get_params().keys()\n",
    "    clean = {}\n",
    "\n",
    "    for key, value in params.items():\n",
    "\n",
    "        # Skip invalid params\n",
    "        if key not in valid_params:\n",
    "            continue\n",
    "\n",
    "        # Convert string 'None' to Python None\n",
    "        if isinstance(value, str) and value.strip().lower() == \"none\":\n",
    "            clean[key] = None\n",
    "            continue\n",
    "\n",
    "        # Convert NaN to None\n",
    "        if isinstance(value, float) and np.isnan(value):\n",
    "            clean[key] = None\n",
    "            continue\n",
    "\n",
    "        # Convert float-like integers to real ints\n",
    "        if isinstance(value, float) and value.is_integer():\n",
    "            clean[key] = int(value)\n",
    "            continue\n",
    "\n",
    "        # Leave everything else unchanged\n",
    "        clean[key] = value\n",
    "\n",
    "    return clean\n",
    "\n",
    "params.pop(\"R2\");\n",
    "params = sanitize_params(RandomForestRegressor, params=params)\n",
    "params['random_state'] = 42\n",
    "\n",
    "# feed the params to model, with random_state as 42\n",
    "model = RandomForestRegressor(**params);\n",
    "\n",
    "# Start Evaluating Model performance. Get R2, MAE, RMSE\n",
    "cv_Scores = {\"R2\" : None, \"MAE\" : None, \"MSE\" : None, \"MedAE\" : None};\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42);\n",
    "\n",
    "scorers = {\n",
    "    \"R2\": \"r2\",\n",
    "    \"MAE\": make_scorer(mean_absolute_error, greater_is_better=False),\n",
    "    \"MSE\": make_scorer(mean_squared_error, greater_is_better=False),\n",
    "    \"MedAE\" : make_scorer(median_absolute_error, greater_is_better=False)\n",
    "}\n",
    "\n",
    "for score_type, scorer in scorers.items() :\n",
    "    score = cross_val_score(estimator=model, scoring=scorer, X=X, y=y, cv=kf, n_jobs=-1, verbose=0).mean()\n",
    "    if score_type in [\"MAE\", \"MSE\", \"MedAE\"] :\n",
    "        score = -score;\n",
    "    \n",
    "    cv_Scores[score_type] = score;\n",
    "\n",
    "df = pd.DataFrame(cv_Scores, index=[0])\n",
    "\n",
    "# save the evaluation results\n",
    "os.makedirs(f\"{RESULT_DIR}Evaluations/\", exist_ok=True);\n",
    "df.to_csv(f\"{RESULT_DIR}Evaluations/{CURRENT_MODEL}_Evaluation_Report.csv\",index=False);\n",
    "# ====<DONE EVAlUATING THE MODEL>====\n",
    "\n",
    "# Train the model on our X and y \n",
    "model.fit(X,y)\n",
    "\n",
    "def predict_viability(model, cancer_type, coumarin_type, dose, time, \n",
    "                      cancer_encoder, coumarin_encoder):\n",
    "    \"\"\"\n",
    "    Predict viability for a single input or a list of inputs.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: trained sklearn regressor\n",
    "    - cancer_type: string or list of strings\n",
    "    - coumarin_type: string or list of strings\n",
    "    - dose: float or list of floats\n",
    "    - time: float or list of floats\n",
    "    - cancer_encoder: LabelEncoder for cancer types\n",
    "    - coumarin_encoder: LabelEncoder for coumarin types (general) or specific coumarin\n",
    "\n",
    "    Returns:\n",
    "    - predicted viability (float or np.array)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure inputs are lists\n",
    "    if not isinstance(cancer_type, list):\n",
    "        cancer_type = [cancer_type]\n",
    "        coumarin_type = [coumarin_type]\n",
    "        dose = [dose]\n",
    "        time = [time]\n",
    "\n",
    "    # Encode categorical variables\n",
    "    cancer_encoded = cancer_encoder.transform(cancer_type)\n",
    "    coumarin_encoded = coumarin_encoder.transform(coumarin_type)\n",
    "\n",
    "    # Build DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'Cancer Type': cancer_encoded,\n",
    "        'Coumarin Type': coumarin_encoded,\n",
    "        'Coumarin Dose': dose,\n",
    "        'Time': time\n",
    "    })\n",
    "\n",
    "    # Predict\n",
    "    predictions = model.predict(df)\n",
    "\n",
    "    # If input was a single value, return single prediction\n",
    "    if len(predictions) == 1:\n",
    "        return predictions[0]\n",
    "    return predictions\n",
    "\n",
    "predicted_viability = predict_viability(\n",
    "    model=model,\n",
    "    cancer_type=\"Colon\",        # example cancer type\n",
    "    coumarin_type=\"Auraptene\", # example coumarin\n",
    "    dose=75,                    # dose value\n",
    "    time=72,                    # time value\n",
    "    cancer_encoder=CancerType_Encoder,\n",
    "    coumarin_encoder=CoumarinType_Encoder\n",
    ")\n",
    "\n",
    "print(f\"Viability with a dose of 240 (galbanic acid) at 72h time point: {predicted_viability}\")\n",
    "doses = [91, 75, 71];\n",
    "times = [24,48,72];\n",
    "\n",
    "for d, t in zip(doses, times) :\n",
    "    predicted_viability = predict_viability(\n",
    "    model=model,\n",
    "    cancer_type=\"Colon\",        # example cancer type\n",
    "    coumarin_type=\"Auraptene\", # example coumarin\n",
    "    dose=d,                    # dose value\n",
    "    time=t,                    # time value\n",
    "    cancer_encoder= CancerType_Encoder,\n",
    "    coumarin_encoder= CoumarinType_Encoder\n",
    "    )\n",
    "    print(f\"Predicted Viability with Dose {d} (auraptene) at time {t} is: {predicted_viability}\");\n",
    "\n",
    "\n",
    "os.makedirs(f\"{RESULT_DIR}/ModelFile/\", exist_ok=True);\n",
    "dump(model, f\"{RESULT_DIR}/ModelFile/{CURRENT_MODEL}.joblib\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c8faa2",
   "metadata": {},
   "source": [
    "## SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8fbb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, median_absolute_error, make_scorer\n",
    "import os\n",
    "import sys\n",
    "from joblib import dump\n",
    "\n",
    "# Please Change the paths to match your own enviroment.(in case of failure that is)\n",
    "DATA_PATH = 'Total_Data.csv'\n",
    "\n",
    "CURRENT_MODEL = \"SVR\";\n",
    "\n",
    "RESULT_DIR = os.path.join(os.getcwd(), f'TrainingResults/Models/{CURRENT_MODEL}/')\n",
    "os.makedirs(RESULT_DIR, exist_ok=True)\n",
    "\n",
    "mainData = pd.read_csv(DATA_PATH);\n",
    "\n",
    "mainData = mainData[['Cancer Type', 'Coumarin Type', 'Coumarin Dose', 'Time', 'Viability']].dropna();\n",
    "\n",
    "allowed_times_NoAuraptene = [24, 48, 72]\n",
    "allowed_times_ForAuraptene = [24, 48, 72, 96]\n",
    "\n",
    "coumarins = ['Auraptene', 'Esculetin', 'Galbanic Acid', 'Umbelliprenin'];\n",
    "\n",
    "# ====<Pre-Processing and GMM filtering>====\n",
    "\n",
    "#First filter the main data and save it in data.\n",
    "cancer_counts = mainData['Cancer Type'].value_counts().to_dict()\n",
    "count_df = pd.DataFrame(list(cancer_counts.items()), columns=['Cancer Type', 'Sample Count'])\n",
    "\n",
    "#Initialize the gmm model\n",
    "gmm = GaussianMixture(n_components=2, random_state=42);\n",
    "gmm.fit(count_df[['Sample Count']])\n",
    "threshold = np.mean(gmm.means_.flatten())\n",
    "\n",
    "count_df['Reliability'] = count_df['Sample Count'].apply(\n",
    "    lambda x: 'Reliable' if x >= threshold else 'Unreliable'\n",
    ")\n",
    "\n",
    "reliable_cancers = count_df[count_df['Reliability'] == 'Reliable']['Cancer Type'].tolist()\n",
    "reliable_data = mainData[mainData['Cancer Type'].isin(reliable_cancers)].copy()\n",
    "\n",
    "data = reliable_data;\n",
    "CancerType_Encoder = LabelEncoder();\n",
    "CoumarinType_Encoder = LabelEncoder();\n",
    "\n",
    "data['Coumarin Type'] = CoumarinType_Encoder.fit_transform(data['Coumarin Type'])\n",
    "data['Cancer Type'] = CancerType_Encoder.fit_transform(data['Cancer Type'])\n",
    "\n",
    "# Filter out the unneeded times for the general data\n",
    "data = data[\n",
    "    ((data['Coumarin Type'] == 'Auraptene') & data['Time'].isin(allowed_times_ForAuraptene)) |\n",
    "    ((data['Coumarin Type'] != 'Auraptene') & data['Time'].isin(allowed_times_NoAuraptene))\n",
    "]\n",
    "\n",
    "\n",
    "# Wether we intend to do grid searching on the model or not is denoted the variable below:\n",
    "DO_GRIDSEARCH = False;\n",
    "\n",
    "# Set your X and y here, incase you want general training or training on a specific coumarin.\n",
    "\n",
    "X = data[['Cancer Type', 'Coumarin Type', 'Coumarin Dose', 'Time']].copy(); # Order must be ['Cancer Type', 'Coumarin Type', 'Coumarin Dose', 'Time']\n",
    "y = data['Viability'].copy(); # Viability column\n",
    "\n",
    "# ====<BEGIN GRID SEARCHING>====\n",
    "# Grid searching is done here, the program stops after grid searching and the parameters and the scores are all saved in reports directory:\n",
    "if DO_GRIDSEARCH :\n",
    "    \n",
    "    gs_Estimator = SVR(random_state=42);\n",
    "    \n",
    "    # The parameters for the search.\n",
    "    gs_parameters = {\n",
    "        \"C\": [0.1, 1, 10, 50, 100, 300],           \n",
    "        \"gamma\": [\"scale\", \"auto\", 0.1, 0.01, 0.001],\n",
    "        \"epsilon\": [0.01, 0.05, 0.1, 0.2],\n",
    "        \"kernel\": [\"rbf\"],                         \n",
    "        \"shrinking\": [True, False]\n",
    "    }\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42);\n",
    "    gs = GridSearchCV(estimator=gs_Estimator,\n",
    "                                scoring='r2',\n",
    "                                param_grid=gs_parameters,\n",
    "                                cv=kf,\n",
    "                                n_jobs=-1,\n",
    "                                verbose=1\n",
    "                                );\n",
    "    \n",
    "    gs.fit(X, y);\n",
    "\n",
    "    BEST_MODEL_PARAMETERS = gs.best_params_;\n",
    "    BEST_MODEL_R2_SCORE = gs.best_score_;\n",
    "\n",
    "    dict = BEST_MODEL_PARAMETERS.copy()\n",
    "    dict['R2'] = BEST_MODEL_R2_SCORE;\n",
    "    \n",
    "    df = pd.DataFrame(dict, index=[0]);\n",
    "\n",
    "    # Save the best found parameters\n",
    "    os.makedirs(f\"{RESULT_DIR}Best_Paremeters/\", exist_ok=True);\n",
    "    df.to_csv(f\"{RESULT_DIR}Best_Paremeters/{CURRENT_MODEL}_GS_BestParameters.csv\",index=False);\n",
    "\n",
    "    sys.exit(0);\n",
    "# ====<END OF GRID SEARCHING>====\n",
    "\n",
    "# ====<START EVALUATING MODEL>====\n",
    "# Get the model parameters post GridSearching\n",
    "params = pd.read_csv(f\"{RESULT_DIR}Best_Paremeters/{CURRENT_MODEL}_GS_BestParameters.csv\").iloc[0].to_dict();\n",
    "\n",
    "# Helper function to make sure the hyperParameters are read correctly.\n",
    "def sanitize_params(estimator, params):\n",
    "    \n",
    "    \"\"\"\n",
    "    Cleans and fixes parameter types before passing them to sklearn models.\n",
    "    - Converts floats representing ints into int\n",
    "    - Converts 'None' strings to None\n",
    "    - Converts NaN to None\n",
    "    - Removes unexpected params\n",
    "    \"\"\"\n",
    "\n",
    "    valid_params = estimator().get_params().keys()\n",
    "    clean = {}\n",
    "\n",
    "    for key, value in params.items():\n",
    "\n",
    "        # Skip invalid params\n",
    "        if key not in valid_params:\n",
    "            continue\n",
    "\n",
    "        # Convert string 'None' to Python None\n",
    "        if isinstance(value, str) and value.strip().lower() == \"none\":\n",
    "            clean[key] = None\n",
    "            continue\n",
    "\n",
    "        # Convert NaN to None\n",
    "        if isinstance(value, float) and np.isnan(value):\n",
    "            clean[key] = None\n",
    "            continue\n",
    "\n",
    "        # Convert float-like integers to real ints\n",
    "        if isinstance(value, float) and value.is_integer():\n",
    "            clean[key] = int(value)\n",
    "            continue\n",
    "\n",
    "        # Leave everything else unchanged\n",
    "        clean[key] = value\n",
    "\n",
    "    return clean\n",
    "\n",
    "params.pop(\"R2\");\n",
    "params = sanitize_params(SVR, params=params)\n",
    "params['random_state'] = 42\n",
    "\n",
    "# feed the params to model, with random_state as 42\n",
    "model = SVR(**params);\n",
    "\n",
    "# Start Evaluating Model performance. Get R2, MAE, RMSE\n",
    "cv_Scores = {\"R2\" : None, \"MAE\" : None, \"MSE\" : None, \"MedAE\" : None};\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42);\n",
    "\n",
    "scorers = {\n",
    "    \"R2\": \"r2\",\n",
    "    \"MAE\": make_scorer(mean_absolute_error, greater_is_better=False),\n",
    "    \"MSE\": make_scorer(mean_squared_error, greater_is_better=False),\n",
    "    \"MedAE\" : make_scorer(median_absolute_error, greater_is_better=False)\n",
    "}\n",
    "\n",
    "for score_type, scorer in scorers.items() :\n",
    "    score = cross_val_score(estimator=model, scoring=scorer, X=X, y=y, cv=kf, n_jobs=-1, verbose=0).mean()\n",
    "    if score_type in [\"MAE\", \"MSE\", \"MedAE\"] :\n",
    "        score = -score;\n",
    "    \n",
    "    cv_Scores[score_type] = score;\n",
    "\n",
    "df = pd.DataFrame(cv_Scores, index=[0])\n",
    "\n",
    "# save the evaluation results\n",
    "os.makedirs(f\"{RESULT_DIR}Evaluations/\", exist_ok=True);\n",
    "df.to_csv(f\"{RESULT_DIR}Evaluations/{CURRENT_MODEL}_Evaluation_Report.csv\",index=False);\n",
    "# ====<DONE EVAlUATING THE MODEL>====\n",
    "\n",
    "# Train the model on our X and y \n",
    "model.fit(X,y)\n",
    "\n",
    "def predict_viability(model, cancer_type, coumarin_type, dose, time, \n",
    "                      cancer_encoder, coumarin_encoder):\n",
    "    \"\"\"\n",
    "    Predict viability for a single input or a list of inputs.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: trained sklearn regressor\n",
    "    - cancer_type: string or list of strings\n",
    "    - coumarin_type: string or list of strings\n",
    "    - dose: float or list of floats\n",
    "    - time: float or list of floats\n",
    "    - cancer_encoder: LabelEncoder for cancer types\n",
    "    - coumarin_encoder: LabelEncoder for coumarin types (general) or specific coumarin\n",
    "\n",
    "    Returns:\n",
    "    - predicted viability (float or np.array)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure inputs are lists\n",
    "    if not isinstance(cancer_type, list):\n",
    "        cancer_type = [cancer_type]\n",
    "        coumarin_type = [coumarin_type]\n",
    "        dose = [dose]\n",
    "        time = [time]\n",
    "\n",
    "    # Encode categorical variables\n",
    "    cancer_encoded = cancer_encoder.transform(cancer_type)\n",
    "    coumarin_encoded = coumarin_encoder.transform(coumarin_type)\n",
    "\n",
    "    # Build DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'Cancer Type': cancer_encoded,\n",
    "        'Coumarin Type': coumarin_encoded,\n",
    "        'Coumarin Dose': dose,\n",
    "        'Time': time\n",
    "    })\n",
    "\n",
    "    # Predict\n",
    "    predictions = model.predict(df)\n",
    "\n",
    "    # If input was a single value, return single prediction\n",
    "    if len(predictions) == 1:\n",
    "        return predictions[0]\n",
    "    return predictions\n",
    "\n",
    "predicted_viability = predict_viability(\n",
    "    model=model,\n",
    "    cancer_type=\"Colon\",        # example cancer type\n",
    "    coumarin_type=\"Auraptene\", # example coumarin\n",
    "    dose=75,                    # dose value\n",
    "    time=72,                    # time value\n",
    "    cancer_encoder=CancerType_Encoder,\n",
    "    coumarin_encoder=CoumarinType_Encoder\n",
    ")\n",
    "\n",
    "print(f\"Viability with a dose of 240 (galbanic acid) at 72h time point: {predicted_viability}\")\n",
    "doses = [91, 75, 71];\n",
    "times = [24,48,72];\n",
    "\n",
    "for d, t in zip(doses, times) :\n",
    "    predicted_viability = predict_viability(\n",
    "    model=model,\n",
    "    cancer_type=\"Colon\",        # example cancer type\n",
    "    coumarin_type=\"Auraptene\", # example coumarin\n",
    "    dose=d,                    # dose value\n",
    "    time=t,                    # time value\n",
    "    cancer_encoder= CancerType_Encoder,\n",
    "    coumarin_encoder= CoumarinType_Encoder\n",
    "    )\n",
    "    print(f\"Predicted Viability with Dose {d} (auraptene) at time {t} is: {predicted_viability}\");\n",
    "\n",
    "\n",
    "os.makedirs(f\"{RESULT_DIR}/ModelFile/\", exist_ok=True);\n",
    "dump(model, f\"{RESULT_DIR}/ModelFile/{CURRENT_MODEL}.joblib\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4731f51",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60d03ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, median_absolute_error, make_scorer\n",
    "import os\n",
    "import sys\n",
    "from joblib import dump\n",
    "\n",
    "# Please Change the paths to match your own enviroment.(in case of failure that is)\n",
    "DATA_PATH = 'Total_Data.csv'\n",
    "\n",
    "CURRENT_MODEL = \"Lasso\";\n",
    "\n",
    "RESULT_DIR = os.path.join(os.getcwd(), f'TrainingResults/Models/{CURRENT_MODEL}/')\n",
    "os.makedirs(RESULT_DIR, exist_ok=True)\n",
    "\n",
    "mainData = pd.read_csv(DATA_PATH);\n",
    "\n",
    "mainData = mainData[['Cancer Type', 'Coumarin Type', 'Coumarin Dose', 'Time', 'Viability']].dropna();\n",
    "\n",
    "allowed_times_NoAuraptene = [24, 48, 72]\n",
    "allowed_times_ForAuraptene = [24, 48, 72, 96]\n",
    "\n",
    "coumarins = ['Auraptene', 'Esculetin', 'Galbanic Acid', 'Umbelliprenin'];\n",
    "\n",
    "# ====<Pre-Processing and GMM filtering>====\n",
    "\n",
    "#First filter the main data and save it in data.\n",
    "cancer_counts = mainData['Cancer Type'].value_counts().to_dict()\n",
    "count_df = pd.DataFrame(list(cancer_counts.items()), columns=['Cancer Type', 'Sample Count'])\n",
    "\n",
    "#Initialize the gmm model\n",
    "gmm = GaussianMixture(n_components=2, random_state=42);\n",
    "gmm.fit(count_df[['Sample Count']])\n",
    "threshold = np.mean(gmm.means_.flatten())\n",
    "\n",
    "count_df['Reliability'] = count_df['Sample Count'].apply(\n",
    "    lambda x: 'Reliable' if x >= threshold else 'Unreliable'\n",
    ")\n",
    "\n",
    "reliable_cancers = count_df[count_df['Reliability'] == 'Reliable']['Cancer Type'].tolist()\n",
    "reliable_data = mainData[mainData['Cancer Type'].isin(reliable_cancers)].copy()\n",
    "\n",
    "data = reliable_data;\n",
    "CancerType_Encoder = LabelEncoder();\n",
    "CoumarinType_Encoder = LabelEncoder();\n",
    "\n",
    "data['Coumarin Type'] = CoumarinType_Encoder.fit_transform(data['Coumarin Type'])\n",
    "data['Cancer Type'] = CancerType_Encoder.fit_transform(data['Cancer Type'])\n",
    "\n",
    "# Filter out the unneeded times for the general data\n",
    "data = data[\n",
    "    ((data['Coumarin Type'] == 'Auraptene') & data['Time'].isin(allowed_times_ForAuraptene)) |\n",
    "    ((data['Coumarin Type'] != 'Auraptene') & data['Time'].isin(allowed_times_NoAuraptene))\n",
    "]\n",
    "\n",
    "\n",
    "# Wether we intend to do grid searching on the model or not is denoted the variable below:\n",
    "DO_GRIDSEARCH = False;\n",
    "\n",
    "# Set your X and y here, incase you want general training or training on a specific coumarin.\n",
    "\n",
    "X = data[['Cancer Type', 'Coumarin Type', 'Coumarin Dose', 'Time']].copy(); # Order must be ['Cancer Type', 'Coumarin Type', 'Coumarin Dose', 'Time']\n",
    "y = data['Viability'].copy(); # Viability column\n",
    "\n",
    "# ====<BEGIN GRID SEARCHING>====\n",
    "# Grid searching is done here, the program stops after grid searching and the parameters and the scores are all saved in reports directory:\n",
    "if DO_GRIDSEARCH :\n",
    "    \n",
    "    gs_Estimator = Lasso(random_state=42);\n",
    "    \n",
    "    # The parameters for the search.\n",
    "    gs_parameters = {\n",
    "        \"alpha\": [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0],\n",
    "        \"fit_intercept\": [True, False],\n",
    "        \"max_iter\": [1000, 5000],\n",
    "        \"selection\": ['cyclic', 'random']\n",
    "    }\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42);\n",
    "    gs = GridSearchCV(estimator=gs_Estimator,\n",
    "                                scoring='r2',\n",
    "                                param_grid=gs_parameters,\n",
    "                                cv=kf,\n",
    "                                n_jobs=-1,\n",
    "                                verbose=1\n",
    "                                );\n",
    "    \n",
    "    gs.fit(X, y);\n",
    "\n",
    "    BEST_MODEL_PARAMETERS = gs.best_params_;\n",
    "    BEST_MODEL_R2_SCORE = gs.best_score_;\n",
    "\n",
    "    dict = BEST_MODEL_PARAMETERS.copy()\n",
    "    dict['R2'] = BEST_MODEL_R2_SCORE;\n",
    "    \n",
    "    df = pd.DataFrame(dict, index=[0]);\n",
    "\n",
    "    # Save the best found parameters\n",
    "    os.makedirs(f\"{RESULT_DIR}Best_Paremeters/\", exist_ok=True);\n",
    "    df.to_csv(f\"{RESULT_DIR}Best_Paremeters/{CURRENT_MODEL}_GS_BestParameters.csv\",index=False);\n",
    "\n",
    "    sys.exit(0);\n",
    "# ====<END OF GRID SEARCHING>====\n",
    "\n",
    "# ====<START EVALUATING MODEL>====\n",
    "# Get the model parameters post GridSearching\n",
    "params = pd.read_csv(f\"{RESULT_DIR}Best_Paremeters/{CURRENT_MODEL}_GS_BestParameters.csv\").iloc[0].to_dict();\n",
    "\n",
    "# Helper function to make sure the hyperParameters are read correctly.\n",
    "def sanitize_params(estimator, params):\n",
    "    \n",
    "    \"\"\"\n",
    "    Cleans and fixes parameter types before passing them to sklearn models.\n",
    "    - Converts floats representing ints into int\n",
    "    - Converts 'None' strings to None\n",
    "    - Converts NaN to None\n",
    "    - Removes unexpected params\n",
    "    \"\"\"\n",
    "\n",
    "    valid_params = estimator().get_params().keys()\n",
    "    clean = {}\n",
    "\n",
    "    for key, value in params.items():\n",
    "\n",
    "        # Skip invalid params\n",
    "        if key not in valid_params:\n",
    "            continue\n",
    "\n",
    "        # Convert string 'None' to Python None\n",
    "        if isinstance(value, str) and value.strip().lower() == \"none\":\n",
    "            clean[key] = None\n",
    "            continue\n",
    "\n",
    "        # Convert NaN to None\n",
    "        if isinstance(value, float) and np.isnan(value):\n",
    "            clean[key] = None\n",
    "            continue\n",
    "\n",
    "        # Convert float-like integers to real ints\n",
    "        if isinstance(value, float) and value.is_integer():\n",
    "            clean[key] = int(value)\n",
    "            continue\n",
    "\n",
    "        # Leave everything else unchanged\n",
    "        clean[key] = value\n",
    "\n",
    "    return clean\n",
    "\n",
    "params.pop(\"R2\");\n",
    "params = sanitize_params(Lasso, params=params)\n",
    "params['random_state'] = 42\n",
    "\n",
    "# feed the params to model, with random_state as 42\n",
    "model = Lasso(**params);\n",
    "\n",
    "# Start Evaluating Model performance. Get R2, MAE, RMSE\n",
    "cv_Scores = {\"R2\" : None, \"MAE\" : None, \"MSE\" : None, \"MedAE\" : None};\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42);\n",
    "\n",
    "scorers = {\n",
    "    \"R2\": \"r2\",\n",
    "    \"MAE\": make_scorer(mean_absolute_error, greater_is_better=False),\n",
    "    \"MSE\": make_scorer(mean_squared_error, greater_is_better=False),\n",
    "    \"MedAE\" : make_scorer(median_absolute_error, greater_is_better=False)\n",
    "}\n",
    "\n",
    "for score_type, scorer in scorers.items() :\n",
    "    score = cross_val_score(estimator=model, scoring=scorer, X=X, y=y, cv=kf, n_jobs=-1, verbose=0).mean()\n",
    "    if score_type in [\"MAE\", \"MSE\", \"MedAE\"] :\n",
    "        score = -score;\n",
    "    \n",
    "    cv_Scores[score_type] = score;\n",
    "\n",
    "df = pd.DataFrame(cv_Scores, index=[0])\n",
    "\n",
    "# save the evaluation results\n",
    "os.makedirs(f\"{RESULT_DIR}Evaluations/\", exist_ok=True);\n",
    "df.to_csv(f\"{RESULT_DIR}Evaluations/{CURRENT_MODEL}_Evaluation_Report.csv\",index=False);\n",
    "# ====<DONE EVAlUATING THE MODEL>====\n",
    "\n",
    "# Train the model on our X and y \n",
    "model.fit(X,y)\n",
    "\n",
    "def predict_viability(model, cancer_type, coumarin_type, dose, time, \n",
    "                      cancer_encoder, coumarin_encoder):\n",
    "    \"\"\"\n",
    "    Predict viability for a single input or a list of inputs.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: trained sklearn regressor\n",
    "    - cancer_type: string or list of strings\n",
    "    - coumarin_type: string or list of strings\n",
    "    - dose: float or list of floats\n",
    "    - time: float or list of floats\n",
    "    - cancer_encoder: LabelEncoder for cancer types\n",
    "    - coumarin_encoder: LabelEncoder for coumarin types (general) or specific coumarin\n",
    "\n",
    "    Returns:\n",
    "    - predicted viability (float or np.array)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure inputs are lists\n",
    "    if not isinstance(cancer_type, list):\n",
    "        cancer_type = [cancer_type]\n",
    "        coumarin_type = [coumarin_type]\n",
    "        dose = [dose]\n",
    "        time = [time]\n",
    "\n",
    "    # Encode categorical variables\n",
    "    cancer_encoded = cancer_encoder.transform(cancer_type)\n",
    "    coumarin_encoded = coumarin_encoder.transform(coumarin_type)\n",
    "\n",
    "    # Build DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'Cancer Type': cancer_encoded,\n",
    "        'Coumarin Type': coumarin_encoded,\n",
    "        'Coumarin Dose': dose,\n",
    "        'Time': time\n",
    "    })\n",
    "\n",
    "    # Predict\n",
    "    predictions = model.predict(df)\n",
    "\n",
    "    # If input was a single value, return single prediction\n",
    "    if len(predictions) == 1:\n",
    "        return predictions[0]\n",
    "    return predictions\n",
    "\n",
    "predicted_viability = predict_viability(\n",
    "    model=model,\n",
    "    cancer_type=\"Colon\",        # example cancer type\n",
    "    coumarin_type=\"Auraptene\", # example coumarin\n",
    "    dose=75,                    # dose value\n",
    "    time=72,                    # time value\n",
    "    cancer_encoder=CancerType_Encoder,\n",
    "    coumarin_encoder=CoumarinType_Encoder\n",
    ")\n",
    "\n",
    "print(f\"Viability with a dose of 240 (galbanic acid) at 72h time point: {predicted_viability}\")\n",
    "doses = [91, 75, 71];\n",
    "times = [24,48,72];\n",
    "\n",
    "for d, t in zip(doses, times) :\n",
    "    predicted_viability = predict_viability(\n",
    "    model=model,\n",
    "    cancer_type=\"Colon\",        # example cancer type\n",
    "    coumarin_type=\"Auraptene\", # example coumarin\n",
    "    dose=d,                    # dose value\n",
    "    time=t,                    # time value\n",
    "    cancer_encoder= CancerType_Encoder,\n",
    "    coumarin_encoder= CoumarinType_Encoder\n",
    "    )\n",
    "    print(f\"Predicted Viability with Dose {d} (auraptene) at time {t} is: {predicted_viability}\");\n",
    "\n",
    "\n",
    "os.makedirs(f\"{RESULT_DIR}/ModelFile/\", exist_ok=True);\n",
    "dump(model, f\"{RESULT_DIR}/ModelFile/{CURRENT_MODEL}.joblib\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d08b91",
   "metadata": {},
   "source": [
    "## Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5b1857",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, median_absolute_error, make_scorer\n",
    "import os\n",
    "import sys\n",
    "from joblib import dump\n",
    "\n",
    "# Please Change the paths to match your own enviroment.(in case of failure that is)\n",
    "DATA_PATH = 'Total_Data.csv'\n",
    "\n",
    "CURRENT_MODEL = \"Ridge\";\n",
    "\n",
    "RESULT_DIR = os.path.join(os.getcwd(), f'TrainingResults/Models/{CURRENT_MODEL}/')\n",
    "os.makedirs(RESULT_DIR, exist_ok=True)\n",
    "\n",
    "mainData = pd.read_csv(DATA_PATH);\n",
    "\n",
    "mainData = mainData[['Cancer Type', 'Coumarin Type', 'Coumarin Dose', 'Time', 'Viability']].dropna();\n",
    "\n",
    "allowed_times_NoAuraptene = [24, 48, 72]\n",
    "allowed_times_ForAuraptene = [24, 48, 72, 96]\n",
    "\n",
    "coumarins = ['Auraptene', 'Esculetin', 'Galbanic Acid', 'Umbelliprenin'];\n",
    "\n",
    "# ====<Pre-Processing and GMM filtering>====\n",
    "\n",
    "#First filter the main data and save it in data.\n",
    "cancer_counts = mainData['Cancer Type'].value_counts().to_dict()\n",
    "count_df = pd.DataFrame(list(cancer_counts.items()), columns=['Cancer Type', 'Sample Count'])\n",
    "\n",
    "#Initialize the gmm model\n",
    "gmm = GaussianMixture(n_components=2, random_state=42);\n",
    "gmm.fit(count_df[['Sample Count']])\n",
    "threshold = np.mean(gmm.means_.flatten())\n",
    "\n",
    "count_df['Reliability'] = count_df['Sample Count'].apply(\n",
    "    lambda x: 'Reliable' if x >= threshold else 'Unreliable'\n",
    ")\n",
    "\n",
    "reliable_cancers = count_df[count_df['Reliability'] == 'Reliable']['Cancer Type'].tolist()\n",
    "reliable_data = mainData[mainData['Cancer Type'].isin(reliable_cancers)].copy()\n",
    "\n",
    "data = reliable_data;\n",
    "CancerType_Encoder = LabelEncoder();\n",
    "CoumarinType_Encoder = LabelEncoder();\n",
    "\n",
    "data['Coumarin Type'] = CoumarinType_Encoder.fit_transform(data['Coumarin Type'])\n",
    "data['Cancer Type'] = CancerType_Encoder.fit_transform(data['Cancer Type'])\n",
    "\n",
    "# Filter out the unneeded times for the general data\n",
    "data = data[\n",
    "    ((data['Coumarin Type'] == 'Auraptene') & data['Time'].isin(allowed_times_ForAuraptene)) |\n",
    "    ((data['Coumarin Type'] != 'Auraptene') & data['Time'].isin(allowed_times_NoAuraptene))\n",
    "]\n",
    "\n",
    "\n",
    "# Wether we intend to do grid searching on the model or not is denoted the variable below:\n",
    "DO_GRIDSEARCH = False;\n",
    "\n",
    "# Set your X and y here, incase you want general training or training on a specific coumarin.\n",
    "\n",
    "X = data[['Cancer Type', 'Coumarin Type', 'Coumarin Dose', 'Time']].copy(); # Order must be ['Cancer Type', 'Coumarin Type', 'Coumarin Dose', 'Time']\n",
    "y = data['Viability'].copy(); # Viability column\n",
    "\n",
    "# ====<BEGIN GRID SEARCHING>====\n",
    "# Grid searching is done here, the program stops after grid searching and the parameters and the scores are all saved in reports directory:\n",
    "if DO_GRIDSEARCH :\n",
    "    \n",
    "    gs_Estimator = Ridge(random_state=42);\n",
    "    \n",
    "    # The parameters for the search.\n",
    "    gs_parameters = {\n",
    "        'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'fit_intercept': [True, False],\n",
    "        'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sag', 'saga'],\n",
    "        'tol': [1e-4, 1e-3, 1e-2, 1e-1],\n",
    "        'max_iter': [None, 1000, 5000]\n",
    "    }\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42);\n",
    "    gs = GridSearchCV(estimator=gs_Estimator,\n",
    "                                scoring='r2',\n",
    "                                param_grid=gs_parameters,\n",
    "                                cv=kf,\n",
    "                                n_jobs=-1,\n",
    "                                verbose=1\n",
    "                                );\n",
    "    \n",
    "    gs.fit(X, y);\n",
    "\n",
    "    BEST_MODEL_PARAMETERS = gs.best_params_;\n",
    "    BEST_MODEL_R2_SCORE = gs.best_score_;\n",
    "\n",
    "    dict = BEST_MODEL_PARAMETERS.copy()\n",
    "    dict['R2'] = BEST_MODEL_R2_SCORE;\n",
    "    \n",
    "    df = pd.DataFrame(dict, index=[0]);\n",
    "\n",
    "    # Save the best found parameters\n",
    "    os.makedirs(f\"{RESULT_DIR}Best_Paremeters/\", exist_ok=True);\n",
    "    df.to_csv(f\"{RESULT_DIR}Best_Paremeters/{CURRENT_MODEL}_GS_BestParameters.csv\",index=False);\n",
    "\n",
    "    sys.exit(0);\n",
    "# ====<END OF GRID SEARCHING>====\n",
    "\n",
    "# ====<START EVALUATING MODEL>====\n",
    "# Get the model parameters post GridSearching\n",
    "params = pd.read_csv(f\"{RESULT_DIR}Best_Paremeters/{CURRENT_MODEL}_GS_BestParameters.csv\").iloc[0].to_dict();\n",
    "\n",
    "# Helper function to make sure the hyperParameters are read correctly.\n",
    "def sanitize_params(estimator, params):\n",
    "    \n",
    "    \"\"\"\n",
    "    Cleans and fixes parameter types before passing them to sklearn models.\n",
    "    - Converts floats representing ints into int\n",
    "    - Converts 'None' strings to None\n",
    "    - Converts NaN to None\n",
    "    - Removes unexpected params\n",
    "    \"\"\"\n",
    "\n",
    "    valid_params = estimator().get_params().keys()\n",
    "    clean = {}\n",
    "\n",
    "    for key, value in params.items():\n",
    "\n",
    "        # Skip invalid params\n",
    "        if key not in valid_params:\n",
    "            continue\n",
    "\n",
    "        # Convert string 'None' to Python None\n",
    "        if isinstance(value, str) and value.strip().lower() == \"none\":\n",
    "            clean[key] = None\n",
    "            continue\n",
    "\n",
    "        # Convert NaN to None\n",
    "        if isinstance(value, float) and np.isnan(value):\n",
    "            clean[key] = None\n",
    "            continue\n",
    "\n",
    "        # Convert float-like integers to real ints\n",
    "        if isinstance(value, float) and value.is_integer():\n",
    "            clean[key] = int(value)\n",
    "            continue\n",
    "\n",
    "        # Leave everything else unchanged\n",
    "        clean[key] = value\n",
    "\n",
    "    return clean\n",
    "\n",
    "params.pop(\"R2\");\n",
    "params = sanitize_params(Ridge, params=params)\n",
    "params['random_state'] = 42\n",
    "\n",
    "# feed the params to model, with random_state as 42\n",
    "model = Ridge(**params);\n",
    "\n",
    "# Start Evaluating Model performance. Get R2, MAE, RMSE\n",
    "cv_Scores = {\"R2\" : None, \"MAE\" : None, \"MSE\" : None, \"MedAE\" : None};\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42);\n",
    "\n",
    "scorers = {\n",
    "    \"R2\": \"r2\",\n",
    "    \"MAE\": make_scorer(mean_absolute_error, greater_is_better=False),\n",
    "    \"MSE\": make_scorer(mean_squared_error, greater_is_better=False),\n",
    "    \"MedAE\" : make_scorer(median_absolute_error, greater_is_better=False)\n",
    "}\n",
    "\n",
    "for score_type, scorer in scorers.items() :\n",
    "    score = cross_val_score(estimator=model, scoring=scorer, X=X, y=y, cv=kf, n_jobs=-1, verbose=0).mean()\n",
    "    if score_type in [\"MAE\", \"MSE\", \"MedAE\"] :\n",
    "        score = -score;\n",
    "    \n",
    "    cv_Scores[score_type] = score;\n",
    "\n",
    "df = pd.DataFrame(cv_Scores, index=[0])\n",
    "\n",
    "# save the evaluation results\n",
    "os.makedirs(f\"{RESULT_DIR}Evaluations/\", exist_ok=True);\n",
    "df.to_csv(f\"{RESULT_DIR}Evaluations/{CURRENT_MODEL}_Evaluation_Report.csv\",index=False);\n",
    "# ====<DONE EVAlUATING THE MODEL>====\n",
    "\n",
    "# Train the model on our X and y \n",
    "model.fit(X,y)\n",
    "\n",
    "def predict_viability(model, cancer_type, coumarin_type, dose, time, \n",
    "                      cancer_encoder, coumarin_encoder):\n",
    "    \"\"\"\n",
    "    Predict viability for a single input or a list of inputs.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: trained sklearn regressor\n",
    "    - cancer_type: string or list of strings\n",
    "    - coumarin_type: string or list of strings\n",
    "    - dose: float or list of floats\n",
    "    - time: float or list of floats\n",
    "    - cancer_encoder: LabelEncoder for cancer types\n",
    "    - coumarin_encoder: LabelEncoder for coumarin types (general) or specific coumarin\n",
    "\n",
    "    Returns:\n",
    "    - predicted viability (float or np.array)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure inputs are lists\n",
    "    if not isinstance(cancer_type, list):\n",
    "        cancer_type = [cancer_type]\n",
    "        coumarin_type = [coumarin_type]\n",
    "        dose = [dose]\n",
    "        time = [time]\n",
    "\n",
    "    # Encode categorical variables\n",
    "    cancer_encoded = cancer_encoder.transform(cancer_type)\n",
    "    coumarin_encoded = coumarin_encoder.transform(coumarin_type)\n",
    "\n",
    "    # Build DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'Cancer Type': cancer_encoded,\n",
    "        'Coumarin Type': coumarin_encoded,\n",
    "        'Coumarin Dose': dose,\n",
    "        'Time': time\n",
    "    })\n",
    "\n",
    "    # Predict\n",
    "    predictions = model.predict(df)\n",
    "\n",
    "    # If input was a single value, return single prediction\n",
    "    if len(predictions) == 1:\n",
    "        return predictions[0]\n",
    "    return predictions\n",
    "\n",
    "predicted_viability = predict_viability(\n",
    "    model=model,\n",
    "    cancer_type=\"Colon\",        # example cancer type\n",
    "    coumarin_type=\"Auraptene\", # example coumarin\n",
    "    dose=75,                    # dose value\n",
    "    time=72,                    # time value\n",
    "    cancer_encoder=CancerType_Encoder,\n",
    "    coumarin_encoder=CoumarinType_Encoder\n",
    ")\n",
    "\n",
    "print(f\"Viability with a dose of 240 (galbanic acid) at 72h time point: {predicted_viability}\")\n",
    "doses = [91, 75, 71];\n",
    "times = [24,48,72];\n",
    "\n",
    "for d, t in zip(doses, times) :\n",
    "    predicted_viability = predict_viability(\n",
    "    model=model,\n",
    "    cancer_type=\"Colon\",        # example cancer type\n",
    "    coumarin_type=\"Auraptene\", # example coumarin\n",
    "    dose=d,                    # dose value\n",
    "    time=t,                    # time value\n",
    "    cancer_encoder= CancerType_Encoder,\n",
    "    coumarin_encoder= CoumarinType_Encoder\n",
    "    )\n",
    "    print(f\"Predicted Viability with Dose {d} (auraptene) at time {t} is: {predicted_viability}\");\n",
    "\n",
    "\n",
    "os.makedirs(f\"{RESULT_DIR}/ModelFile/\", exist_ok=True);\n",
    "dump(model, f\"{RESULT_DIR}/ModelFile/{CURRENT_MODEL}.joblib\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc0eb87",
   "metadata": {},
   "source": [
    "## Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6834442",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, median_absolute_error, make_scorer\n",
    "import os\n",
    "import sys\n",
    "from joblib import dump\n",
    "\n",
    "# Please Change the paths to match your own enviroment.(in case of failure that is)\n",
    "DATA_PATH = 'Total_Data.csv'\n",
    "\n",
    "CURRENT_MODEL = \"ElasticNet\";\n",
    "\n",
    "RESULT_DIR = os.path.join(os.getcwd(), f'TrainingResults/Models/{CURRENT_MODEL}/')\n",
    "os.makedirs(RESULT_DIR, exist_ok=True)\n",
    "\n",
    "mainData = pd.read_csv(DATA_PATH);\n",
    "\n",
    "mainData = mainData[['Cancer Type', 'Coumarin Type', 'Coumarin Dose', 'Time', 'Viability']].dropna();\n",
    "\n",
    "allowed_times_NoAuraptene = [24, 48, 72]\n",
    "allowed_times_ForAuraptene = [24, 48, 72, 96]\n",
    "\n",
    "coumarins = ['Auraptene', 'Esculetin', 'Galbanic Acid', 'Umbelliprenin'];\n",
    "\n",
    "# ====<Pre-Processing and GMM filtering>====\n",
    "\n",
    "#First filter the main data and save it in data.\n",
    "cancer_counts = mainData['Cancer Type'].value_counts().to_dict()\n",
    "count_df = pd.DataFrame(list(cancer_counts.items()), columns=['Cancer Type', 'Sample Count'])\n",
    "\n",
    "#Initialize the gmm model\n",
    "gmm = GaussianMixture(n_components=2, random_state=42);\n",
    "gmm.fit(count_df[['Sample Count']])\n",
    "threshold = np.mean(gmm.means_.flatten())\n",
    "\n",
    "count_df['Reliability'] = count_df['Sample Count'].apply(\n",
    "    lambda x: 'Reliable' if x >= threshold else 'Unreliable'\n",
    ")\n",
    "\n",
    "reliable_cancers = count_df[count_df['Reliability'] == 'Reliable']['Cancer Type'].tolist()\n",
    "reliable_data = mainData[mainData['Cancer Type'].isin(reliable_cancers)].copy()\n",
    "\n",
    "data = reliable_data;\n",
    "CancerType_Encoder = LabelEncoder();\n",
    "CoumarinType_Encoder = LabelEncoder();\n",
    "\n",
    "data['Coumarin Type'] = CoumarinType_Encoder.fit_transform(data['Coumarin Type'])\n",
    "data['Cancer Type'] = CancerType_Encoder.fit_transform(data['Cancer Type'])\n",
    "\n",
    "# Filter out the unneeded times for the general data\n",
    "data = data[\n",
    "    ((data['Coumarin Type'] == 'Auraptene') & data['Time'].isin(allowed_times_ForAuraptene)) |\n",
    "    ((data['Coumarin Type'] != 'Auraptene') & data['Time'].isin(allowed_times_NoAuraptene))\n",
    "]\n",
    "\n",
    "\n",
    "# Wether we intend to do grid searching on the model or not is denoted the variable below:\n",
    "DO_GRIDSEARCH = False;\n",
    "\n",
    "# Set your X and y here, incase you want general training or training on a specific coumarin.\n",
    "\n",
    "X = data[['Cancer Type', 'Coumarin Type', 'Coumarin Dose', 'Time']].copy(); # Order must be ['Cancer Type', 'Coumarin Type', 'Coumarin Dose', 'Time']\n",
    "y = data['Viability'].copy(); # Viability column\n",
    "\n",
    "# ====<BEGIN GRID SEARCHING>====\n",
    "# Grid searching is done here, the program stops after grid searching and the parameters and the scores are all saved in reports directory:\n",
    "if DO_GRIDSEARCH :\n",
    "    \n",
    "    gs_Estimator = ElasticNet(random_state=42);\n",
    "    \n",
    "    # The parameters for the search.\n",
    "    gs_parameters = {\n",
    "         \"alpha\": [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0],\n",
    "        \"l1_ratio\": [0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "        \"fit_intercept\": [True, False],\n",
    "        \"max_iter\": [1000, 5000],\n",
    "        \"selection\": ['cyclic', 'random']\n",
    "    }\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42);\n",
    "    gs = GridSearchCV(estimator=gs_Estimator,\n",
    "                                scoring='r2',\n",
    "                                param_grid=gs_parameters,\n",
    "                                cv=kf,\n",
    "                                n_jobs=-1,\n",
    "                                verbose=1\n",
    "                                );\n",
    "    \n",
    "    gs.fit(X, y);\n",
    "\n",
    "    BEST_MODEL_PARAMETERS = gs.best_params_;\n",
    "    BEST_MODEL_R2_SCORE = gs.best_score_;\n",
    "\n",
    "    dict = BEST_MODEL_PARAMETERS.copy()\n",
    "    dict['R2'] = BEST_MODEL_R2_SCORE;\n",
    "    \n",
    "    df = pd.DataFrame(dict, index=[0]);\n",
    "\n",
    "    # Save the best found parameters\n",
    "    os.makedirs(f\"{RESULT_DIR}Best_Paremeters/\", exist_ok=True);\n",
    "    df.to_csv(f\"{RESULT_DIR}Best_Paremeters/{CURRENT_MODEL}_GS_BestParameters.csv\",index=False);\n",
    "\n",
    "    sys.exit(0);\n",
    "# ====<END OF GRID SEARCHING>====\n",
    "\n",
    "# ====<START EVALUATING MODEL>====\n",
    "# Get the model parameters post GridSearching\n",
    "params = pd.read_csv(f\"{RESULT_DIR}Best_Paremeters/{CURRENT_MODEL}_GS_BestParameters.csv\").iloc[0].to_dict();\n",
    "\n",
    "# Helper function to make sure the hyperParameters are read correctly.\n",
    "def sanitize_params(estimator, params):\n",
    "    \n",
    "    \"\"\"\n",
    "    Cleans and fixes parameter types before passing them to sklearn models.\n",
    "    - Converts floats representing ints into int\n",
    "    - Converts 'None' strings to None\n",
    "    - Converts NaN to None\n",
    "    - Removes unexpected params\n",
    "    \"\"\"\n",
    "\n",
    "    valid_params = estimator().get_params().keys()\n",
    "    clean = {}\n",
    "\n",
    "    for key, value in params.items():\n",
    "\n",
    "        # Skip invalid params\n",
    "        if key not in valid_params:\n",
    "            continue\n",
    "\n",
    "        # Convert string 'None' to Python None\n",
    "        if isinstance(value, str) and value.strip().lower() == \"none\":\n",
    "            clean[key] = None\n",
    "            continue\n",
    "\n",
    "        # Convert NaN to None\n",
    "        if isinstance(value, float) and np.isnan(value):\n",
    "            clean[key] = None\n",
    "            continue\n",
    "\n",
    "        # Convert float-like integers to real ints\n",
    "        if isinstance(value, float) and value.is_integer():\n",
    "            clean[key] = int(value)\n",
    "            continue\n",
    "\n",
    "        # Leave everything else unchanged\n",
    "        clean[key] = value\n",
    "\n",
    "    return clean\n",
    "\n",
    "params.pop(\"R2\");\n",
    "params = sanitize_params(ElasticNet, params=params)\n",
    "params['random_state'] = 42\n",
    "\n",
    "# feed the params to model, with random_state as 42\n",
    "model = ElasticNet(**params);\n",
    "\n",
    "# Start Evaluating Model performance. Get R2, MAE, RMSE\n",
    "cv_Scores = {\"R2\" : None, \"MAE\" : None, \"MSE\" : None, \"MedAE\" : None};\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42);\n",
    "\n",
    "scorers = {\n",
    "    \"R2\": \"r2\",\n",
    "    \"MAE\": make_scorer(mean_absolute_error, greater_is_better=False),\n",
    "    \"MSE\": make_scorer(mean_squared_error, greater_is_better=False),\n",
    "    \"MedAE\" : make_scorer(median_absolute_error, greater_is_better=False)\n",
    "}\n",
    "\n",
    "for score_type, scorer in scorers.items() :\n",
    "    score = cross_val_score(estimator=model, scoring=scorer, X=X, y=y, cv=kf, n_jobs=-1, verbose=0).mean()\n",
    "    if score_type in [\"MAE\", \"MSE\", \"MedAE\"] :\n",
    "        score = -score;\n",
    "    \n",
    "    cv_Scores[score_type] = score;\n",
    "\n",
    "df = pd.DataFrame(cv_Scores, index=[0])\n",
    "\n",
    "# save the evaluation results\n",
    "os.makedirs(f\"{RESULT_DIR}Evaluations/\", exist_ok=True);\n",
    "df.to_csv(f\"{RESULT_DIR}Evaluations/{CURRENT_MODEL}_Evaluation_Report.csv\",index=False);\n",
    "# ====<DONE EVAlUATING THE MODEL>====\n",
    "\n",
    "# Train the model on our X and y \n",
    "model.fit(X,y)\n",
    "\n",
    "def predict_viability(model, cancer_type, coumarin_type, dose, time, \n",
    "                      cancer_encoder, coumarin_encoder):\n",
    "    \"\"\"\n",
    "    Predict viability for a single input or a list of inputs.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: trained sklearn regressor\n",
    "    - cancer_type: string or list of strings\n",
    "    - coumarin_type: string or list of strings\n",
    "    - dose: float or list of floats\n",
    "    - time: float or list of floats\n",
    "    - cancer_encoder: LabelEncoder for cancer types\n",
    "    - coumarin_encoder: LabelEncoder for coumarin types (general) or specific coumarin\n",
    "\n",
    "    Returns:\n",
    "    - predicted viability (float or np.array)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure inputs are lists\n",
    "    if not isinstance(cancer_type, list):\n",
    "        cancer_type = [cancer_type]\n",
    "        coumarin_type = [coumarin_type]\n",
    "        dose = [dose]\n",
    "        time = [time]\n",
    "\n",
    "    # Encode categorical variables\n",
    "    cancer_encoded = cancer_encoder.transform(cancer_type)\n",
    "    coumarin_encoded = coumarin_encoder.transform(coumarin_type)\n",
    "\n",
    "    # Build DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'Cancer Type': cancer_encoded,\n",
    "        'Coumarin Type': coumarin_encoded,\n",
    "        'Coumarin Dose': dose,\n",
    "        'Time': time\n",
    "    })\n",
    "\n",
    "    # Predict\n",
    "    predictions = model.predict(df)\n",
    "\n",
    "    # If input was a single value, return single prediction\n",
    "    if len(predictions) == 1:\n",
    "        return predictions[0]\n",
    "    return predictions\n",
    "\n",
    "predicted_viability = predict_viability(\n",
    "    model=model,\n",
    "    cancer_type=\"Colon\",        # example cancer type\n",
    "    coumarin_type=\"Auraptene\", # example coumarin\n",
    "    dose=75,                    # dose value\n",
    "    time=72,                    # time value\n",
    "    cancer_encoder=CancerType_Encoder,\n",
    "    coumarin_encoder=CoumarinType_Encoder\n",
    ")\n",
    "\n",
    "print(f\"Viability with a dose of 240 (galbanic acid) at 72h time point: {predicted_viability}\")\n",
    "doses = [91, 75, 71];\n",
    "times = [24,48,72];\n",
    "\n",
    "for d, t in zip(doses, times) :\n",
    "    predicted_viability = predict_viability(\n",
    "    model=model,\n",
    "    cancer_type=\"Colon\",        # example cancer type\n",
    "    coumarin_type=\"Auraptene\", # example coumarin\n",
    "    dose=d,                    # dose value\n",
    "    time=t,                    # time value\n",
    "    cancer_encoder= CancerType_Encoder,\n",
    "    coumarin_encoder= CoumarinType_Encoder\n",
    "    )\n",
    "    print(f\"Predicted Viability with Dose {d} (auraptene) at time {t} is: {predicted_viability}\");\n",
    "\n",
    "\n",
    "os.makedirs(f\"{RESULT_DIR}/ModelFile/\", exist_ok=True);\n",
    "dump(model, f\"{RESULT_DIR}/ModelFile/{CURRENT_MODEL}.joblib\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76632453",
   "metadata": {},
   "source": [
    "## Figure 2 (FrameWork FlowChart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6009516c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9d04041",
   "metadata": {},
   "source": [
    "## Figure 3-A & 3-B (Cancer and Coumarin distributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5db155",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Total_Data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pyplot \u001b[38;5;28;01mas\u001b[39;00m plt;\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcm\u001b[39;00m;\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m DATA = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTotal_Data.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m;\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(DATA.columns);\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# ====<Pie chart for the coumarin distribution in the dataset>====\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/torch-env/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/torch-env/lib/python3.13/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/torch-env/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/torch-env/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/torch-env/lib/python3.13/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'Total_Data.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "from matplotlib import pyplot as plt;\n",
    "import matplotlib.cm as cm;\n",
    "import os\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "\n",
    "DATA = pd.read_csv(\"Total_Data.csv\");\n",
    "\n",
    "print(DATA.columns);\n",
    "\n",
    "# ====<Pie chart for the coumarin distribution in the dataset>====\n",
    "percentages = DATA[\"Coumarin Type\"].value_counts(normalize=True) * 100;\n",
    "colors = cm.Blues(np.linspace(0.4, 0.9, len(percentages)))\n",
    "\n",
    "fig_Coumarin = plt.figure();\n",
    "ax = fig_Coumarin.add_subplot();\n",
    "labels = ['Esculetin', 'Umbelliprenin', 'Auraptene', 'Galbanic acid'];\n",
    "# print(percentages.index)\n",
    "ax.pie(percentages, labels=labels, \n",
    "       autopct='%1.1f%%', startangle=90,\n",
    "       wedgeprops={'width': 0.5}, pctdistance=0.75,\n",
    "       colors=colors\n",
    "       )\n",
    "\n",
    "ax.set_title(\"Coumarin distribution\");\n",
    "ax.axis('equal');\n",
    "plt.show()\n",
    "\n",
    "# ====<Bar chart for the Cancer Type distribution in the dataset>====\n",
    "\n",
    "percentages = DATA[\"Cancer Type\"].value_counts(normalize=True) * 100\n",
    "\n",
    "# Colors\n",
    "colors = cm.plasma(np.linspace(0.4, 0.9, len(percentages)))\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(16, 9))\n",
    "xaxis = ['Colorectal', 'Leukemia\\nLymphoma', 'Prostate', 'Lung', 'Breast', 'Gastric',\n",
    "       'Pancreatic', 'Skin', 'Oral', 'Glioma', 'Liver', 'Ovarian', 'Renal',\n",
    "       'Bone', 'Biliary\\nTract', 'Cervical', 'Salivary\\nGland', 'Melanoma']\n",
    "bars = plt.bar(\n",
    "    xaxis,\n",
    "    percentages.values,\n",
    "    color=colors,\n",
    ")\n",
    "\n",
    "# Add percentage labels on top of bars\n",
    "for bar, value in zip(bars, percentages.values):\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        bar.get_height(),\n",
    "        f\"{value:.1f}%\",\n",
    "        ha='center',\n",
    "        va='bottom',\n",
    "        fontsize=9\n",
    "    )\n",
    "\n",
    "plt.title(\"Cancer Type Distribution\", fontsize=16)\n",
    "plt.xlabel(\"Cancer Type\", fontsize=12)\n",
    "plt.ylabel(\"Percentage (%)\", fontsize=12)\n",
    "# plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
